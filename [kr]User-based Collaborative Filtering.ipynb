{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-based Collaborative filtering\n",
    "\n",
    "MovieLens 데이터셋을 이용해 가장 기본적인 Collaborative Filtering을 다뤄보겠습니다.\n",
    "\n",
    "* 유저가 평가하지 않은 영화의 점수를 user-item matrix를 이용해 예측\n",
    "* 유사도는 cosine similarity와 Pearson correlation coefficient 두 가지를 이용해서 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocess the datasets\n",
    "\n",
    "MovieLens 데이터는 가장 작은 100K를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwoncheol/deep/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/kwoncheol/deep/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "path = './datasets/'\n",
    "ratings = np.array(pd.read_csv(path + \"ratings.csv\"))#.astype(int)\n",
    "movies = np.array(pd.read_csv(path + \"movies.csv\"))\n",
    "\n",
    "u_count = int(max(ratings[:,0])+1) # number of users\n",
    "m_count = len(movies) # number of movies\n",
    "\n",
    "# 9125의 영화들이 저장돼있지만 영화의 ID는 1~164979의 값을 갖는다\n",
    "# 유저-아이템 행렬의 사이즈를 [유저 x 9125]로 만들기 위해 \n",
    "# 각 영화의 Idx를 찾아갈 수 있는 딕셔너리를 만든다\n",
    "\n",
    "mv_idx = {}\n",
    "\n",
    "for i in range(m_count):\n",
    "    mv_idx[movies.T[0][i]] = i\n",
    "\n",
    "# 유저-아이템 행렬\n",
    "r_mat = np.zeros([u_count,m_count])\n",
    "\n",
    "for i in range(ratings.shape[0]):\n",
    "    r_mat[int(ratings[i][0]),mv_idx[ratings[i][1]]] = ratings[i][2]\n",
    "    \n",
    "# 유저별 rating 평균\n",
    "r_mean = np.zeros([u_count])\n",
    "\n",
    "for i in range(u_count):\n",
    "    r_mean[i] = np.mean(r_mat[i,np.nonzero(r_mat[i])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize technique 1\n",
    "\n",
    "유저별로 각 rating값에서 자신의 평균을 빼줍니다.\n",
    "\n",
    "cosine similarity사용시 rating하지 않은 아이템을 negative로 처리하는 것을 방지해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(u_count):\n",
    "    r_mat[i,r_mat[i] != 0] = r_mat[i,r_mat[i] != 0] - r_mean[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize technuque 2    \n",
    "      \n",
    "rating이 3보다 크면 1, 3보다 작거나 평가를 하지 않았으면 0으로 값을 변경합니다.\n",
    "이 예제에서는 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(self.ratings.shape[0]):\n",
    "#    self.r_mat[self.ratings[i][0],self.ratings[i][1]] = 0 if self.ratings[i][2]>=3 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pearson Correlation measure function\n",
    "\n",
    "Scipy에 PCC 함수가 있지만 직접 정의해서 사용하겠습니다. \n",
    "유사도를 측정하려는 두 유저의 인덱스를 받아 PCC값을 반환하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_pears(a, b): \n",
    "    '''\n",
    "    Pearson Correlation Coefficient function\n",
    "        \n",
    "    Arguments:\n",
    "        a - Index of user A\n",
    "        b - Index of user B\n",
    "\n",
    "    '''\n",
    "    # 해당 유저가 rating한 item들을 찾기 쉽게 행렬을 뒤집어줍니다.\n",
    "    \n",
    "    aidx = ratings.T[0] == a\n",
    "    bidx = ratings.T[0] == b\n",
    "\n",
    "    br_idx = np.intersect1d(ratings[aidx][:,1],ratings[bidx][:,1]).astype(int)\n",
    "\n",
    "    # 교집합이 없다면 0 반환\n",
    "        \n",
    "    if(len(br_idx) == 0):\n",
    "        return 0\n",
    "    \n",
    "    idx_list = []\n",
    "\n",
    "    for i in range(len(br_idx)):\n",
    "        idx_list.append(mv_idx[br_idx[i]])\n",
    "\n",
    "    sim = np.sum((r_mat[a,idx_list]-r_mean[a])*(r_mat[b,idx_list]-r_mean[b])) \\\n",
    "        / (np.sqrt(np.sum(np.square(r_mat[a,idx_list]-r_mean[a]))) \\\n",
    "        * np.sqrt(np.sum(np.square(r_mat[b,idx_list]-r_mean[b]))))\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict users' unknown ratings\n",
    "\n",
    "특정 유저와 특정 영화에 대한 rating 점수를 예측하는 함수를 만들겠습니다. \n",
    "\n",
    "유저 x가 영화 m에 어떤 점수를 줄 것인지 예측한다고 가정해보겠습니다.\n",
    "1. 영화m에 대한 rating 점수를 갖고 있는 유저들을 찾는다. 그 유저들과 유저x의 유사도를 측정해 유저x와 가장 유사한 유저 K명을 구한다.\n",
    "\n",
    "2. K명의 유저들이 그 영화에 어떤 rating을 주었는지를 이용해 우리가 원하는 유저의 rating을 예측한다.\n",
    "\n",
    "### 점수예측은 두 가지 방법을 사용합니다.\n",
    "1) 유사한 K명이 해당 영화에 준 점수를 합한 후 K로 나눈다.\n",
    "\n",
    "2) 각 유저와의 유사도와 그 유저들이 영화에 준 점수를 곱한 후 이를 모두 합한다. 그 값을 유저들의 유사도의 합으로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(u, mov, k=10, sim_met='pearson'):\n",
    "    '''\n",
    "    Prediction for item 'mov' of user 'u'\n",
    "        \n",
    "    Arguments:\n",
    "        u - 점수를 예측하고자 하는 유저  \n",
    "        mov - 유저의 점수를 예측하고자 하는 영화\n",
    "        k - predict에 사용할 유사한 유저의 수 (Default = 10)\n",
    "            \n",
    "        sim_met - 유사도측정에 사용할 함수 (Default = 'pearson')\n",
    "              \n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Find users who have rated 'mov'\n",
    "    rated_u = np.array(np.nonzero(r_mat[:,mov]))\n",
    "        \n",
    "    if rated_u.shape[1] == 0 or (rated_u.shape[1] == 1 and rated_u[0,0] == u):\n",
    "        #print(\"No users who have rated this movie\")\n",
    "        return (0,0)\n",
    "        \n",
    "    rated_u = rated_u.flatten()\n",
    "        \n",
    "    sims = {}\n",
    "    for i in range(rated_u.shape[0]):\n",
    "        if rated_u[i] == u:\n",
    "            continue\n",
    "            \n",
    "        if sim_met is 'pearson':\n",
    "            sim = my_pears(u,rated_u[i])\n",
    "        else:\n",
    "            sim = cosine(r_mat[u,:],r_mat[rated_u[i],:])\n",
    "\n",
    "        if len(sims) < k:\n",
    "            sims[rated_u[i]] = sim\n",
    "\n",
    "        # 현재 유저 i와의 유사도가 sims 내의 가장 유사도가 작은 유저보다 크다면 가작 작은 값을 가진 유저를 지우고\n",
    "        # 현재 유저 i를 sims에 넣는다\n",
    "        elif sim > sims[min_val]:\n",
    "            sims.pop(min_val)\n",
    "            sims[rated_u[i]] = sim\n",
    "\n",
    "        min_val = min(sims, key=lambda k:sims[k])\n",
    "\n",
    "\n",
    "    p_ver_1 = np.sum(r_mat[[*sims],mov]) / (rated_u.shape[0] if rated_u.shape[0] < k else k)\n",
    "    p_ver_2 = np.sum(r_mat[[*sims],mov] * list(sims.values())) / np.sum(list(sims.values()))\n",
    "\n",
    "    return p_ver_1, p_ver_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "유저3을 예로 직접 rating한 값과 collaborative filtering을 이용해 측정한 값을 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  56,  100,  219,  239,  266,  284,  320,  321,  341,  472,  521,\n",
       "        524,  525,  527,  617,  642,  699,  954,  966,  990, 1025, 1118,\n",
       "       1253, 1359, 1455, 1590, 1834, 2010, 2156, 2162, 2173, 2212, 2273,\n",
       "       2288, 2374, 2599, 2804, 3157, 4085, 4259, 4610, 5026, 5127, 5480,\n",
       "       5485, 5904, 6383, 6557, 6601, 6916, 7733])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저3이 점수를 매긴 영화들을 찾는다\n",
    "rated_list = np.array(np.nonzero(r_mat[3,:])).flatten()\n",
    "rated_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 영화 60에 대한 점수를 pearson 함수를 이용해 구해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting values : \t (-0.3416791353532814, -0.3458529191646994)\n",
      "Real rating value :\t -0.5686274509803924\n"
     ]
    }
   ],
   "source": [
    "#pearson\n",
    "print('Predicting values : \\t',predict_score(3,mv_idx[60],sim_met='pearson'))\n",
    "print('Real rating value :\\t', r_mat[3,mv_idx[60]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 같은 영화에 대한 점수를 cosine similarity로 구해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting values : \t (-1.3883074678646374, -1.383321162066603)\n",
      "Real rating value :\t -0.5686274509803924\n"
     ]
    }
   ],
   "source": [
    "#cosine\n",
    "print('Predicting values : \\t',predict_score(3,mv_idx[60],sim_met='cosine'))\n",
    "print('Real rating value :\\t', r_mat[3,mv_idx[60]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCC를 이용한 결과가 조금 더 낫습니다. 영화 247에도 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting values : \t (0.26461344528587805, 0.26247249912838305)\n",
      "Real rating value :\t -0.06862745098039236\n"
     ]
    }
   ],
   "source": [
    "# pearson\n",
    "print('Predicting values : \\t',predict_score(3,mv_idx[247],sim_met='pearson'))\n",
    "print('Real rating value :\\t', r_mat[3,mv_idx[247]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting values : \t (0.20257315610389953, 0.2033382372547101)\n",
      "Real rating value :\t -0.06862745098039236\n"
     ]
    }
   ],
   "source": [
    "#cosine\n",
    "print('Predicting values : \\t',predict_score(3,mv_idx[247],sim_met='cosine'))\n",
    "print('Real rating value :\\t', r_mat[3,mv_idx[247]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이번에는 cosine similarity가 좀 더 나은 결과를 보여주었습니다. 이제 에러를 좀 더 정확하게 측정해보겠습니다.\n",
    "#### 이 노트북의 예제에서는 시간 문제로 100명의 유저의 에러만 측정했습니다.\n",
    "#### 모든 유저에 대한 에러는 영문 노트북에서 측정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_ver1_errors = 0\n",
    "pearson_ver2_errors = 0\n",
    "cosine_ver1_errors = 0\n",
    "cosine_ver2_errors = 0\n",
    "\n",
    "for i in range(100):\n",
    "    rated_mov = np.array(np.nonzero(r_mat[i,:])).flatten()\n",
    "    \n",
    "    for j in rated_mov:\n",
    "        pred_val = predict_score(i,j,sim_met='pearson')\n",
    "        \n",
    "        pearson_ver1_errors = pearson_ver1_errors + np.sqrt(np.square(pred_val[0] - r_mat[i,j]))\n",
    "        pearson_ver2_errors = pearson_ver2_errors + np.sqrt(np.square(pred_val[1] - r_mat[i,j]))\n",
    "        \n",
    "        pred_val = predict_score(i,j,sim_met='cosine')\n",
    "        \n",
    "        cosine_ver1_errors = cosine_ver1_errors + np.sqrt(np.square(pred_val[0] - r_mat[i,j]))\n",
    "        cosine_ver2_errors = cosine_ver2_errors + np.sqrt(np.square(pred_val[1] - r_mat[i,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson: \n",
      "\tver 1: 10040\n",
      "\tver 2: 10131\n",
      "cosine: \n",
      "\tver 1: 13436\n",
      "\tver 2: 13559\n"
     ]
    }
   ],
   "source": [
    "print('pearson: \\n\\tver 1: %d\\n\\tver 2: %d'%(pearson_ver1_errors,pearson_ver2_errors))\n",
    "print('cosine: \\n\\tver 1: %d\\n\\tver 2: %d'%(cosine_ver1_errors, cosine_ver2_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 저의 모델에서는 피어슨이 코사인보다는 상당히 나은 결과를 보여줍니다.\n",
    "#### 예측하는 두 가지 방법의 에러는 큰 차이를 보이지는 않습니다. \n",
    "#### 하지만 단순히 K값으로 나눈 ver1이 조금 더 나은 결과를 보여주기는 했습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
